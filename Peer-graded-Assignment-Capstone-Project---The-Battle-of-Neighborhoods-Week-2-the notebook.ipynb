{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Capstone: Find the best neighborhood in Toronto to open a Restaurant Supply Store\n",
    "1. Load all the Data from all the various sources.\n",
    "1.1 Toronto neighborhoods broken down by postal code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " Load the required libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Found the table using beautifulsoup and used Pandas to read it in. \n",
    "res = requests.get('https://en.wikipedia.org/wiki/List_of_postal_codes_of_Canada:_M')\n",
    "soup = BeautifulSoup(res.content,'lxml')\n",
    "table = soup.find_all('table')[0] \n",
    "df = pd.read_html(str(table))\n",
    "\n",
    "\n",
    "# WRANGLE/Transform THE DATA\n",
    "# Convert the list back into a dataframe\n",
    "data = pd.DataFrame(df[0])\n",
    "\n",
    "# Rename the columns as instructed\n",
    "data = data.rename(columns={0:'PostalCode', 1:'Bourough', 2:'Neighborhood'})\n",
    "\n",
    "# Get rid of the first row which contained the table headers from the webpage\n",
    "data = data.iloc[1:]\n",
    "\n",
    "\n",
    "# Only process the cells that have an assigned borough. Ignore cells with a borough that is Not assigned.\n",
    "data = data[~data['Bourough'].str.contains('Not assigned')]\n",
    "\n",
    "\n",
    "# More than one neighborhood can exist in one postal code area. \n",
    "#For example, in the table on the Wikipedia page, you will notice \n",
    "#that M5A is listed twice and has two neighborhoods: Harbourfront \n",
    "#and Regent Park. These two rows will be combined into one row with \n",
    "#the neighborhoods separated with a comma\n",
    "df2=data.groupby(['PostalCode', 'Bourough']).apply(lambda group: ', '.join(group['Neighborhood']))\n",
    "\n",
    "\n",
    "# Convert the Series back into a DataFrame and put the 'Neighbourhood' column label back in\n",
    "df2=df2.to_frame().reset_index()\n",
    "df2 = df2.rename(columns={0:'Neighborhood'})\n",
    "\n",
    "# If a cell has a borough but a Not assigned neighborhood, then the neighborhood will be the same as the borough.\n",
    "df2.loc[df2.Neighborhood == 'Not assigned', 'Neighborhood' ] = df2.Bourough\n",
    "\n",
    "# Display the DataFrame\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Toronto geospatial cooridinates\n",
    "!wget -O to_geo_space.csv http://cocl.us/Geospatial_data\n",
    "\n",
    "#Read into dataframe\n",
    "gf = pd.read_csv('to_geo_space.csv')\n",
    "\n",
    "#rename the coloumns so the match\n",
    "gf = gf.rename(columns={'Postal Code':'PostalCode'})\n",
    "\n",
    "#Merge the Toronto data with geo cooridinate data\n",
    "gf_new = pd.merge(df2, gf, on='PostalCode', how='inner')\n",
    "\n",
    "# display the new dataframe\n",
    "gf_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load this data from Stats Canada\n",
    "df_pop = pd.read_csv('https://www12.statcan.gc.ca/census-recensement/2016/dp-pd/hlt-fst/pd-pl/Tables/File.cfm?T=1201&SR=1&RPP=9999&PR=0&CMA=0&CSD=0&S=22&O=A&Lang=Eng&OFT=CSV',encoding = 'unicode_escape')\n",
    "# Rename the columns appropiatley\n",
    "df_pop = df_pop.rename(columns={'Geographic code':'PostalCode', 'Geographic name':'PostalCod2', 'Province or territory':'Province', 'Incompletely enumerated Indian reserves and Indian settlements, 2016':'Incomplete', 'Population, 2016':'Population_2016', 'Total private dwellings, 2016':'TotalPrivDwellings', 'Private dwellings occupied by usual residents, 2016':'PrivDwellingsOccupied'})\n",
    "df_pop= df_pop.drop(columns=['PostalCod2', 'Province', 'Incomplete', 'TotalPrivDwellings', 'PrivDwellingsOccupied'])\n",
    "\n",
    "# Get rid of the first row \n",
    "df_pop = df_pop.iloc[1:]\n",
    "df_pop.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merge the Toronto Pop data with geo postalcode data\n",
    "gf_new\n",
    "gf_new = pd.merge(df_pop, gf_new, on='PostalCode', how='right')\n",
    "# sort on population\n",
    "gf_new = gf_new.sort_values(by=['Population_2016'], ascending=False)\n",
    "\n",
    "# display the new dataframe\n",
    "gf_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It was easier to extract this data manually from Stats Canada and load it then it was to scrape it.\n",
    "# It was only accessible from indeividual queries per postal code on the statscan web site.\n",
    "df_income = pd.read_csv('TorontoAvgIncomeByPC.csv',encoding = 'unicode_escape')\n",
    "# Rename the after tax income column to a more maanageable name\n",
    "df_income = df_income.rename(columns={\"after-tax income of households in 2015\":\"AfterTaxIncome2015\"})\n",
    "df_income.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merge the Toronto Income data with geo postalcode data\n",
    "\n",
    "gf_new = pd.merge(df_income, gf_new, on='PostalCode', how='right')\n",
    "# get rid of the Nulls\n",
    "gf_new = gf_new.replace('Null', 0)\n",
    "#gf_new cast as float\n",
    "gf_new['AfterTaxIncome2015'] = gf_new['AfterTaxIncome2015'].astype('float64') \n",
    "# Sort on Income\n",
    "gf_new = gf_new.sort_values(by=['AfterTaxIncome2015'], ascending=False)\n",
    "\n",
    "# display the new dataframe\n",
    "gf_new.to_csv('TO_Affluence.csv')\n",
    "gf_new.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Key Observation Toronto Affluence by Neighborhood\n",
    "1.4 What is the Canadian National Average After Tax Income.\n",
    "\n",
    "Again obtained from the Stats Canada Website Canadian families and unattached individuals had a median after-tax income of $57,000 in 2016.\n",
    "1.5 Toronto list of Restaurants or Venues that could potentially use Restaurant Equipment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FourSquare Credentials\n",
    "\n",
    "CLIENT_ID = 'APO00QTF2Y3WAWZUT2YTZXSPZGDGHOYNY5FSI1ARNPVQ2WQU' # your Foursquare ID\n",
    "\n",
    "\n",
    "CLIENT_SECRET = 'RWUKTJGS3Y1GOCBSRX1TMUUFMYPFL2BVV03GVUVIHH3G25UC' # your Foursquare Secret\n",
    "\n",
    "\n",
    "VERSION = '20180605' # Foursquare API version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's explore neighborhoods in our dataframe.\n",
    "import requests # library to handle requests\n",
    "from pandas.io.json import json_normalize # tranform JSON file into a pandas dataframe\n",
    "\n",
    "LIMIT = 200 # limit of number of venues returned by Foursquare API\n",
    "\n",
    "radius = 500 # define radius\n",
    "\n",
    "def getNearbyVenues(names, latitudes, longitudes, radius=500):\n",
    "    \n",
    "    venues_list=[]\n",
    "    for name, lat, lng in zip(names, latitudes, longitudes):\n",
    "        print(name)\n",
    "            \n",
    "        # create the API request URL\n",
    "        url = 'https://api.foursquare.com/v2/venues/explore?&client_id={}&client_secret={}&v={}&ll={},{}&radius={}&limit={}'.format(\n",
    "            CLIENT_ID, \n",
    "            CLIENT_SECRET, \n",
    "            VERSION, \n",
    "            lat, \n",
    "            lng, \n",
    "            radius, \n",
    "            LIMIT)\n",
    "            \n",
    "        # make the GET request\n",
    "        results = requests.get(url).json()[\"response\"]['groups'][0]['items']\n",
    "        \n",
    "        # return only relevant information for each nearby venue\n",
    "        venues_list.append([(\n",
    "            name, \n",
    "            lat, \n",
    "            lng, \n",
    "            v['venue']['name'], \n",
    "            v['venue']['location']['lat'], \n",
    "            v['venue']['location']['lng'],  \n",
    "            v['venue']['categories'][0]['name']) for v in results])\n",
    "\n",
    "    nearby_venues = pd.DataFrame([item for venue_list in venues_list for item in venue_list])\n",
    "    nearby_venues.columns = ['Neighborhood', \n",
    "                  'Neighborhood Latitude', \n",
    "                  'Neighborhood Longitude', \n",
    "                  'Venue', \n",
    "                  'Venue Latitude', \n",
    "                  'Venue Longitude', \n",
    "                  'Venue Category']\n",
    "    \n",
    "    return(nearby_venues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Toronto Bouroughs\n",
    "TO_data = gf_new\n",
    "TO_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all of the Venues\n",
    "TO_venues = getNearbyVenues(names=TO_data['Neighborhood'],\n",
    "                                   latitudes=TO_data['Latitude'],\n",
    "                                   longitudes=TO_data['Longitude']\n",
    "                                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TO_venues.groupby('Neighborhood').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's pick out restaurants from Venue Categories\n",
    "\n",
    "print('Unique Venue Categories:')\n",
    "list(TO_venues['Venue Category'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we manually pick out restaurants or 'features' from the unique venue list and that we want to examine for similiarity during clustering\n",
    "rest_list = ['Steakhouse', 'Coffee Shop', 'Café', 'Ramen Restaurant', 'Indonesian Restaurant', 'Restaurant', 'Japanese Restaurant', \n",
    "             'Fast Food Restaurant', 'Sushi Restaurant', 'Vietnamese Restaurant', 'Pizza Place', 'Sandwich Place', 'Middle Eastern Restaurant', \n",
    "             'Burger Joint', 'American Restaurant', 'Food Court', 'Wings Joint', 'Burrito Place', 'Asian Restaurant', 'Deli / Bodega', \n",
    "             'Greek Restaurant', 'Fried Chicken Joint', 'Airport Food Court', 'Chinese Restaurant', 'Breakfast Spot', 'Mexican Restaurant',\n",
    "             'Indian Restaurant', 'Latin American Restaurant', 'Bar', 'Pub', 'Italian Restaurant', 'French Restaurant', 'Ice Cream Shop', \n",
    "             'Caribbean Restaurant', 'Gastropub', 'Thai Restaurant', 'Cajun / Creole Restaurant', 'Diner', 'Dim Sum Restaurant', 'Seafood Restaurant', \n",
    "             'Food & Drink Shop', 'Noodle House', 'Food', 'Fish & Chips Shop', 'Falafel Restaurant', 'Gourmet Shop', 'Vegetarian / Vegan Restaurant', \n",
    "             'South American Restaurant', 'Korean Restaurant', 'Cuban Restaurant', 'New American Restaurant', 'Malay Restaurant', 'Mac & Cheese Joint',\n",
    "             'Bistro', 'Southern / Soul Food Restaurant', 'Tapas Restaurant',  'Sports Bar', 'Polish Restaurant', 'Ethiopian Restaurant', \n",
    "             'Creperie', 'Sake Bar', 'Persian Restaurant', 'Afghan Restaurant','Mediterranean Restaurant', 'BBQ Joint', 'Jewish Restaurant', \n",
    "             'Comfort Food Restaurant',  'Hakka Restaurant', 'Food Truck', 'Taiwanese Restaurant',  'Snack Place', 'Eastern European Restaurant', \n",
    "             'Dumpling Restaurant', 'Belgian Restaurant', 'Arepa Restaurant', 'Taco Place', 'Doner Restaurant', 'Filipino Restaurant', \n",
    "             'Hotpot Restaurant', 'Poutine Place', 'Salad Place',  'Portuguese Restaurant', 'Modern European Restaurant', 'Empanada Restaurant', \n",
    "             'Irish Pub', 'Molecular Gastronomy Restaurant', 'German Restaurant', 'Brazilian Restaurant', 'Gluten-free Restaurant', 'Soup Place']\n",
    "\n",
    "rest_pd = pd.DataFrame(rest_list)\n",
    "#rest_pd\n",
    "#rename the coloumns so the match\n",
    "rest_pd = rest_pd.rename(columns={0:'Venue Category'})\n",
    "\n",
    "#Join the 2 dataframes as instructed\n",
    "TO_new = pd.merge(TO_venues, rest_pd, on='Venue Category', how='right')\n",
    "\n",
    "# display the new dataframe\n",
    "#TO_new\n",
    "\n",
    "TO_new.groupby('Neighborhood').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one hot encoding\n",
    "TO_new_onehot = pd.get_dummies(TO_new[['Venue Category']], prefix=\"\", prefix_sep=\"\")\n",
    "\n",
    "# add neighborhood column back to dataframe\n",
    "TO_new_onehot['Neighborhood'] = TO_new['Neighborhood'] \n",
    "\n",
    "\n",
    "# move neighborhood column to the first column\n",
    "fixed_columns = [TO_new_onehot.columns[-1]] + list(TO_new_onehot.columns[:-1])\n",
    "TO_new_onehot = TO_new_onehot[fixed_columns]\n",
    "\n",
    "TO_new_onehot.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Analyze each neighbourhood\n",
    "\n",
    "\n",
    "\n",
    "TO_grouped = TO_new_onehot.groupby('Neighborhood').mean().reset_index()\n",
    "TO_grouped.shape\n",
    "\n",
    "\n",
    "TO_grouped.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "2. Begin to Cluster\n",
    "Use silhouette score to find optimal number of clusters to segment the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "TO_grouped_clustering = TO_grouped.drop('Neighborhood', 1)\n",
    "\n",
    "# Use silhouette score to find optimal number of clusters to segment the data\n",
    "kclusters = np.arange(2,10)\n",
    "results = {}\n",
    "for size in kclusters:\n",
    "    model = KMeans(n_clusters = size).fit(TO_grouped_clustering)\n",
    "    predictions = model.predict(TO_grouped_clustering)\n",
    "    results[size] = silhouette_score(TO_grouped_clustering, predictions)\n",
    "\n",
    "best_size = max(results, key=results.get)\n",
    "best_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import k-means from clustering stage\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# set number of clusters\n",
    "kclusters = best_size\n",
    "\n",
    "\n",
    "# run k-means clustering\n",
    "kmeans = KMeans(n_clusters=kclusters, random_state=0).fit(TO_grouped_clustering)\n",
    "\n",
    "# check cluster labels generated for each row in the dataframe\n",
    "kmeans.labels_[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_most_common_venues(row, num_top_venues):\n",
    "    row_categories = row.iloc[1:]\n",
    "    row_categories_sorted = row_categories.sort_values(ascending=False)\n",
    "    return row_categories_sorted.index.values[0:num_top_venues]\n",
    "\n",
    "num_top_venues = 10\n",
    "\n",
    "indicators = ['st', 'nd', 'rd']\n",
    "\n",
    "# create columns according to number of top venues\n",
    "columns = ['Neighborhood']\n",
    "for ind in np.arange(num_top_venues):\n",
    "    try:\n",
    "        columns.append('{}{} Most Common Venue'.format(ind+1, indicators[ind]))\n",
    "    except:\n",
    "        columns.append('{}th Most Common Venue'.format(ind+1))\n",
    "\n",
    "# create a new dataframe\n",
    "neighborhoods_venues_sorted = pd.DataFrame(columns=columns)\n",
    "neighborhoods_venues_sorted['Neighborhood'] = TO_grouped['Neighborhood']\n",
    "\n",
    "for ind in np.arange(TO_grouped.shape[0]):\n",
    "    neighborhoods_venues_sorted.iloc[ind, 1:] = return_most_common_venues(TO_grouped.iloc[ind, :], num_top_venues)\n",
    "\n",
    "neighborhoods_venues_sorted.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merge the Toronto data with geo cooridinate data and make sure it's the right shape\n",
    "TO_labels = pd.merge(TO_data,TO_grouped, on='Neighborhood', how='right')\n",
    "TO_labels.shape\n",
    "\n",
    "\n",
    "TO_labels = TO_labels.drop(columns=['Steakhouse', 'Coffee Shop', 'Café', 'Ramen Restaurant', 'Indonesian Restaurant', 'Restaurant', 'Japanese Restaurant', \n",
    "             'Fast Food Restaurant', 'Sushi Restaurant', 'Vietnamese Restaurant', 'Pizza Place', 'Sandwich Place', 'Middle Eastern Restaurant', \n",
    "             'Burger Joint', 'American Restaurant', 'Food Court', 'Wings Joint', 'Burrito Place', 'Asian Restaurant', 'Deli / Bodega', \n",
    "             'Greek Restaurant', 'Fried Chicken Joint', 'Airport Food Court', 'Chinese Restaurant', 'Breakfast Spot', 'Mexican Restaurant',\n",
    "             'Indian Restaurant', 'Latin American Restaurant', 'Bar', 'Pub', 'Italian Restaurant', 'French Restaurant', 'Ice Cream Shop', \n",
    "             'Caribbean Restaurant', 'Gastropub', 'Thai Restaurant', 'Cajun / Creole Restaurant', 'Diner', 'Dim Sum Restaurant', 'Seafood Restaurant', \n",
    "             'Food & Drink Shop', 'Noodle House', 'Food', 'Fish & Chips Shop', 'Falafel Restaurant', 'Gourmet Shop', 'Vegetarian / Vegan Restaurant', \n",
    "             'South American Restaurant', 'Korean Restaurant', 'Cuban Restaurant', 'New American Restaurant', 'Malay Restaurant', 'Mac & Cheese Joint',\n",
    "             'Bistro', 'Southern / Soul Food Restaurant', 'Tapas Restaurant',  'Sports Bar', 'Polish Restaurant', 'Ethiopian Restaurant', \n",
    "             'Creperie', 'Sake Bar', 'Persian Restaurant', 'Afghan Restaurant','Mediterranean Restaurant', 'BBQ Joint', 'Jewish Restaurant', \n",
    "             'Comfort Food Restaurant',  'Hakka Restaurant', 'Food Truck', 'Taiwanese Restaurant',  'Snack Place', 'Eastern European Restaurant', \n",
    "             'Dumpling Restaurant', 'Belgian Restaurant', 'Arepa Restaurant', 'Taco Place', 'Doner Restaurant', 'Filipino Restaurant', \n",
    "             'Hotpot Restaurant', 'Poutine Place', 'Salad Place',  'Portuguese Restaurant', 'Modern European Restaurant', 'Empanada Restaurant', \n",
    "             'Irish Pub', 'Molecular Gastronomy Restaurant', 'German Restaurant', 'Brazilian Restaurant', 'Gluten-free Restaurant', 'Soup Place'])\n",
    "TO_labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TO_merged = TO_labels\n",
    "\n",
    "# add clustering labels\n",
    "TO_merged['Cluster Labels'] = kmeans.labels_\n",
    "\n",
    "# merge toronto_grouped with toronto_data to add latitude/longitude for each neighborhood\n",
    "TO_merged = TO_merged.join(neighborhoods_venues_sorted.set_index('Neighborhood'), on='Neighborhood')\n",
    "\n",
    "TO_merged.head() # check the last columns!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TO_merged_new1 = TO_merged.loc[TO_merged['Cluster Labels'] == 0, TO_merged.columns[[3, 4] + list(range(5, TO_merged.shape[1]))]]\n",
    "TO_merged_new1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TO_merged_new2 = TO_merged.loc[TO_merged['Cluster Labels'] == 1, TO_merged.columns[[3, 4] + list(range(5, TO_merged.shape[1]))]]\n",
    "TO_merged_new2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Cluster 2 Contains the highest cluster density. We need to find the geographic centroid for this cluster. This is the optimum location for a new Restaurant Supply Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the geographic center of the most dense or like cluster.\n",
    "Cluster_0_coorid = TO_merged_new2[['Latitude', 'Longitude']]\n",
    "Cluster_0_coorid = list(Cluster_0_coorid.values) \n",
    "lat = []\n",
    "long = []\n",
    "\n",
    "\n",
    "\n",
    "for l in Cluster_0_coorid:\n",
    "  lat.append(l[0])\n",
    "  long.append(l[1])\n",
    "\n",
    "\n",
    "\n",
    "Blatitude = sum(lat)/len(lat)\n",
    "Blongitude = sum(long)/len(long)\n",
    "print(Blatitude)\n",
    "print(Blongitude)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Intstall opencage to reverse lookup the cooridinates\n",
    "!pip install opencage\n",
    "from opencage.geocoder import OpenCageGeocode\n",
    "from pprint import pprint\n",
    "\n",
    "key = '1d97b344df184b1cb0d2427663f85ac6'\n",
    "geocoder = OpenCageGeocode(key)\n",
    "\n",
    "results = geocoder.reverse_geocode(Blatitude, Blongitude)\n",
    "pprint(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Obtain the popupstring of the best location\n",
    "popstring = TO_data[TO_data['PostalCode'].str.contains('M4S')]\n",
    "\n",
    "def str_join(*args):\n",
    "    return ''.join(map(str, args))\n",
    "\n",
    "popstring_new = str_join('The Best Neighbourhood to locate a Restaurant Supply Store is in: ', popstring['Neighborhood'].values,  ' in ' ,  popstring['Bourough'].values)\n",
    "\n",
    "\n",
    "print(popstring_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's get the coordinates for Toronto\n",
    "\n",
    "from geopy.geocoders import Nominatim\n",
    "address = 'Toronto, ON'\n",
    "\n",
    "geolocator = Nominatim(user_agent=\"my-application\")\n",
    "location = geolocator.geocode(address)\n",
    "latitude = location.latitude\n",
    "longitude = location.longitude\n",
    "print('The geograpical coordinate of Toronto are {}, {}.'.format(latitude, longitude))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getfolium\n",
    "import folium \n",
    "# Matplotlib and associated plotting modules\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.colors as colors\n",
    "\n",
    "# create map\n",
    "map_clusters = folium.Map(location=[latitude, longitude], zoom_start=11)\n",
    "\n",
    "# set color scheme for the clusters\n",
    "x = np.arange(kclusters)\n",
    "ys = [i+x+(i*x)**2 for i in range(kclusters)]\n",
    "colors_array = cm.rainbow(np.linspace(0, 1, len(ys)))\n",
    "rainbow = [colors.rgb2hex(i) for i in colors_array]\n",
    "\n",
    "# add markers to the map\n",
    "markers_colors = []\n",
    "for lat, lon, poi, cluster in zip(TO_merged['Latitude'], TO_merged['Longitude'], TO_merged['Neighborhood'], TO_merged['Cluster Labels']):\n",
    "    label = folium.Popup(str(poi) + ' Cluster ' + str(cluster), parse_html=True)\n",
    "    folium.CircleMarker(\n",
    "        [lat, lon],\n",
    "        radius=5,\n",
    "        popup=label,\n",
    "        color=rainbow[cluster-1],\n",
    "        fill=True,\n",
    "        fill_color=rainbow[cluster-1],\n",
    "        fill_opacity=0.7).add_to(map_clusters)\n",
    "    \n",
    "folium.CircleMarker([Blatitude, Blongitude],\n",
    "                    radius=50,\n",
    "                    popup='Toronto',\n",
    "                    color='red',\n",
    "                    ).add_to(map_clusters)\n",
    "\n",
    "# Interactive marker\n",
    "map_clusters.add_child(folium.ClickForMarker(popup=popstring_new))\n",
    "       \n",
    "#map_clusters\n",
    "map_clusters.save('map_clusters.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The exact Address to locate would be: 268 Balliol Street, ON M4S 1C2, Canada or lat: 43.6991598, lng: -79.3878871')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Discussion:\n",
    "5.1 Explaining the results\n",
    "\n",
    "As we built our list of neighborhoods with Restaurant venues exclusively we discovered most neighborhoods were similar and the greatest concentration of restaurants was in Central Toronto and downtown Toronto. This might seem obvious but it would also appear that these are some of the most affluent neighborhoods in Toronto so there appears to be correlation. By Locating in the general vicinity of the Exact location my friend could be geographically centered in this cluster and poised to service his restaurant customer base with the greatest efficiency.\n",
    "\n",
    "When we built our our K-Means dataset we used Silhouette analysis to tell us there was a lot of similarity between neighborhoods and the most common restaurants contained with in. Really there was only 2 types of cluster or neighborhoods in greater Toronto. The vast majority of those were in 1 cluster. So Toronto restaurants might be many but they are very homogeneously located near the center of Toronto.\n",
    "\n",
    "Of the 103 Toronto Neighborhoods gathered only 55.3% or 57 Neighborhoods are above the median after-tax income. 37.8% or 39 Neighborhoods are below he median after-tax income. 6.7% or 7 neighborhoods did not register as it appears their populations are too low. It appears that the greatest concentration of affluence is near central Toronto. We decided to keep all neighborhoods in the dataset regardless of income of population as the majority were close enough.\n",
    "Conclusion:\n",
    "\n",
    "I feel confident with the recommendation I have given my friend as it is backed up with demonstrated data analysis. While nothing can ever be 100% certain he will certainly be better informed than he was prior to asking for my help.\n",
    "\n",
    "Much more inference can be obtained with more work. A potential side business for my friend might be assisting new restaurant owners where they might locate a new restaurant, who their competition is and who their clientele might be.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
